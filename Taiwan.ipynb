{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece5978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=256\n",
    "BATCH_SIZE=32\n",
    "dataset=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "\"PlantVillage\",\n",
    "    shuffle=True,\n",
    "    image_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e1968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823cf705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c505e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in dataset.take(1):\n",
    "    normalized_image = (image_batch[0].numpy() / 255.0).astype(\"float32\")\n",
    "    plt.imshow(normalized_image, interpolation='nearest')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a630d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in dataset.take(1):\n",
    "    plt.imshow(image_batch[0].numpy().astype(\"uint8\"), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_batch[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eefe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in dataset.take(1):\n",
    "    for i in range(15):\n",
    "        ax=plt.subplot(3,5,i+1)\n",
    "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[label_batch[i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=0.8\n",
    "len(dataset)*train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c513667",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=dataset.take(516)\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ad764",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds=dataset.skip(516)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size=0.1\n",
    "len(dataset)*val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee1dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds=test_ds.take(64)\n",
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45dca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds=test_ds.skip(64)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865b1079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, shuffle_size=10000):\n",
    "    ds_size = len(ds)\n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)  # Fix the parameter name here\n",
    "    train_ds = ds.take(train_size)\n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7d3aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f11d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f5f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds=val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds=test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6ce8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale=tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    layers.experimental.preprocessing.Rescaling(1.0/255)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation =tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])\n",
    "train_ds = train_ds.map(lambda x,y:(data_augmentation(x, training = True),y)).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff32904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "CHANNELS = 3\n",
    "\n",
    "EPOCHS = 50\n",
    "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 15\n",
    "\n",
    "# Assuming you have a resize_and_rescale layer defined\n",
    "resize_and_rescale = layers.experimental.preprocessing.Rescaling(1./255)\n",
    "\n",
    "model = models.Sequential([\n",
    "    resize_and_rescale,\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),  # Add dropout with a rate of 0.25\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Add dropout before the output layer with a rate of 0.5\n",
    "    layers.Dense(n_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.build(input_shape=input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212b799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a9865",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=val_ds,\n",
    "    verbose=1,\n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82d5a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c980d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16550358",
   "metadata": {},
   "outputs": [],
   "source": [
    "history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae54c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c910815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0baa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=history.history['accuracy']\n",
    "val_acc=history.history[\"val_accuracy\"]\n",
    "loss=history.history[\"loss\"]\n",
    "val_loss=history.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21e330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(EPOCHS),acc,label=\"Training accuracy\")\n",
    "plt.plot(range(EPOCHS),val_acc,label=\"Validation accuracy\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c083c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
    "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for images_batch, labels_batch in test_ds.take(1):\n",
    "    \n",
    "    first_image = images_batch[0].numpy().astype('uint8')\n",
    "    first_label = labels_batch[0].numpy()\n",
    "    \n",
    "    print(\"first image to predict\")\n",
    "    plt.imshow(first_image)\n",
    "    print(\"actual label:\",class_names[first_label])\n",
    "    \n",
    "    batch_prediction = model.predict(images_batch)\n",
    "    print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8892f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in test_ds.take(1):\n",
    "    for i in range(15):\n",
    "        ax = plt.subplot(5, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        predicted_class, confidence = predict(model, images[i].numpy())\n",
    "        actual_class = class_names[labels[i]] \n",
    "        \n",
    "        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
    "        \n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List all items in the directory\n",
    "directory_contents = os.listdir(\"../taiwan\")\n",
    "\n",
    "# Filter out non-integer items\n",
    "numeric_contents = [i for i in directory_contents if i.isdigit()]\n",
    "\n",
    "# Convert to integers and add 0 to the list if no numeric items are found\n",
    "numeric_values = [int(i) for i in numeric_contents] + [0]\n",
    "\n",
    "# Find the maximum and increment\n",
    "model_version = max(numeric_values) + 1\n",
    "\n",
    "# Save the model with the new version\n",
    "model.save(f\"../taiwan/models/{model_version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file exists\n",
    "if os.path.exists( r\"../taiwan/PlantVillage/Pepper__bell___Bacterial_spot/0022d6b7-d47c-4ee2-ae9a-392a53f48647___JR_B.Spot%208964.JPG\"):\n",
    "    print(\"File exists.\")\n",
    "else:\n",
    "    print(\"File does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5744ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the latest model version\n",
    "latest_model_version = 1  # Replace with the actual version number\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model(f\"../taiwan/models/{latest_model_version}\")\n",
    "\n",
    "# Convert the model to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model with standard Python file handling\n",
    "model_path = 'C:/Users/lamas/Desktop/Ml-project/taiwan/model.tflite'\n",
    "try:\n",
    "    with open(model_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    print(\"Model converted and saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33a9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model\n",
    "model_path = 'C:/Users/lamas/Desktop/Ml-project/taiwan/model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get details about the input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input details:\")\n",
    "print(input_details)\n",
    "\n",
    "print(\"\\nOutput details:\")\n",
    "print(output_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8873ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the TFLite model\n",
    "model_path = 'C:/Users/lamas/Desktop/Ml-project/taiwan/model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Load and preprocess an image\n",
    "image_path = r'C:\\Users\\lamas\\Downloads\\le.jpeg'\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(image_path, target_size=(256, 256))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "input_data = img_array.astype(np.float32) / 255.0  # Normalize to the range [0, 1]\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Perform inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get output tensor\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Process or analyze the output_data as needed for your application\n",
    "print(\"Output data:\", output_data)\n",
    "predicted_class_index = np.argmax(output_data)\n",
    "print(\"Predicted class index:\", predicted_class_index)\n",
    "\n",
    "# Visualization (replace this with your actual prediction logic)\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predicted class index: {predicted_class_index}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63612fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c87032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f8dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7f8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
